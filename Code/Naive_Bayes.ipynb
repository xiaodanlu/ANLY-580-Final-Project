{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data without Delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Date                                  Tweets_clean_more  polarity  \\\n",
      "0  2013-01-10  to super clear i dont wish could i mandat anyt...  0.216667   \n",
      "1  2019-01-10  ye get regulatori pushback may avail region go...  0.123333   \n",
      "2  2020-01-10  dome barrel weld made bar pretti good bar need...  0.411111   \n",
      "3  2012-01-11  the exec conf room tesla use call denali i dec...  0.600000   \n",
      "4  2016-01-11                    sad hear david bowi die he amaz -0.500000   \n",
      "\n",
      "   subjectivity sentiment     Label  \n",
      "0      0.525000  positive  Decrease  \n",
      "1      0.490556  positive  Increase  \n",
      "2      0.570988  positive  Decrease  \n",
      "3      1.000000  positive  Increase  \n",
      "4      1.000000  negative  Decrease  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data  = pd.read_csv(\"../Data/Combined.csv\")\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data['Tweets_clean_more'], data['Label'], test_size=0.2, random_state=42)\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "X_train_list = X_train.to_list()\n",
    "X_test_list = X_test.to_list()\n",
    "vectorizer.fit(X_train_list)\n",
    "vectorizer.fit(X_test_list)\n",
    "X_train_clean = vectorizer.transform(X_train_list)\n",
    "X_test_clean = vectorizer.transform(X_test_list)\n",
    "\n",
    "X_train_array = X_train_clean.toarray()\n",
    "X_test_array = X_test_clean.toarray()\n",
    "\n",
    "#X_train_counts = vectorizer.fit_transform(X_train)\n",
    "#tfidf_transformer = TfidfTransformer()\n",
    "#X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "\n",
    "clf = MultinomialNB().fit(X_train_array, y_train)\n",
    "Y_pred = clf.predict(X_test_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def multiclass_roc_auc_score(y_test, y_pred, average=\"micro\"):\n",
    "    lb = LabelBinarizer()\n",
    "    lb.fit(y_test)\n",
    "    y_test = lb.transform(y_test)\n",
    "    y_pred = lb.transform(y_pred)\n",
    "    return roc_auc_score(y_test, y_pred, average=average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.40350877192982454\n",
      "F1 Score: 0.40350877192982454\n",
      "ROC AUC Score: 0.5526315789473684\n",
      "Confusion Matrix: [[66 77  6]\n",
      " [81 47  3]\n",
      " [ 2  1  2]]\n",
      "Classification Report:               precision    recall  f1-score   support\n",
      "\n",
      "    Decrease       0.44      0.44      0.44       149\n",
      "    Increase       0.38      0.36      0.37       131\n",
      "   No Change       0.18      0.40      0.25         5\n",
      "\n",
      "    accuracy                           0.40       285\n",
      "   macro avg       0.33      0.40      0.35       285\n",
      "weighted avg       0.41      0.40      0.40       285\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, f1_score\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, Y_pred))\n",
    "print(\"F1 Score:\", f1_score(y_test, Y_pred, average='micro'))\n",
    "print(\"ROC AUC Score:\", multiclass_roc_auc_score(y_test, Y_pred, average='micro'))\n",
    "print(\"Confusion Matrix:\", confusion_matrix(y_test, Y_pred))\n",
    "print(\"Classification Report:\", classification_report(y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.43859649122807015\n",
      "F1 Score: 0.43859649122807015\n",
      "ROC AUC Score: 0.5789473684210527\n",
      "Confusion Matrix: [[80 64  5]\n",
      " [83 44  4]\n",
      " [ 2  2  1]]\n",
      "Classification Report:               precision    recall  f1-score   support\n",
      "\n",
      "    Decrease       0.48      0.54      0.51       149\n",
      "    Increase       0.40      0.34      0.37       131\n",
      "   No Change       0.10      0.20      0.13         5\n",
      "\n",
      "    accuracy                           0.44       285\n",
      "   macro avg       0.33      0.36      0.34       285\n",
      "weighted avg       0.44      0.44      0.44       285\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "clf = GaussianNB().fit(X_train_array, y_train)\n",
    "Y_pred = clf.predict(X_test_array)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, Y_pred))\n",
    "print(\"F1 Score:\", f1_score(y_test, Y_pred, average='micro'))\n",
    "print(\"ROC AUC Score:\", multiclass_roc_auc_score(y_test, Y_pred, average='micro'))\n",
    "print(\"Confusion Matrix:\", confusion_matrix(y_test, Y_pred))\n",
    "print(\"Classification Report:\", classification_report(y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.42105263157894735\n",
      "F1 Score: 0.42105263157894735\n",
      "ROC AUC Score: 0.5657894736842105\n",
      "Confusion Matrix: [[88 49 12]\n",
      " [90 32  9]\n",
      " [ 5  0  0]]\n",
      "Classification Report:               precision    recall  f1-score   support\n",
      "\n",
      "    Decrease       0.48      0.59      0.53       149\n",
      "    Increase       0.40      0.24      0.30       131\n",
      "   No Change       0.00      0.00      0.00         5\n",
      "\n",
      "    accuracy                           0.42       285\n",
      "   macro avg       0.29      0.28      0.28       285\n",
      "weighted avg       0.43      0.42      0.42       285\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "clf = BernoulliNB().fit(X_train_array, y_train)\n",
    "Y_pred = clf.predict(X_test_array)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, Y_pred))\n",
    "print(\"F1 Score:\", f1_score(y_test, Y_pred, average='micro'))\n",
    "print(\"ROC AUC Score:\", multiclass_roc_auc_score(y_test, Y_pred, average='micro'))\n",
    "print(\"Confusion Matrix:\", confusion_matrix(y_test, Y_pred))\n",
    "print(\"Classification Report:\", classification_report(y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.26666666666666666\n",
      "F1 Score: 0.26666666666666666\n",
      "ROC AUC Score: 0.44999999999999996\n",
      "Confusion Matrix: [[41 60 48]\n",
      " [60 33 38]\n",
      " [ 3  0  2]]\n",
      "Classification Report:               precision    recall  f1-score   support\n",
      "\n",
      "    Decrease       0.39      0.28      0.32       149\n",
      "    Increase       0.35      0.25      0.29       131\n",
      "   No Change       0.02      0.40      0.04         5\n",
      "\n",
      "    accuracy                           0.27       285\n",
      "   macro avg       0.26      0.31      0.22       285\n",
      "weighted avg       0.37      0.27      0.31       285\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import ComplementNB\n",
    "\n",
    "clf = ComplementNB().fit(X_train_array, y_train)\n",
    "Y_pred = clf.predict(X_test_array)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, Y_pred))\n",
    "print(\"F1 Score:\", f1_score(y_test, Y_pred, average='micro'))\n",
    "print(\"ROC AUC Score:\", multiclass_roc_auc_score(y_test, Y_pred, average='micro'))\n",
    "print(\"Confusion Matrix:\", confusion_matrix(y_test, Y_pred))\n",
    "print(\"Classification Report:\", classification_report(y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Delayed 2 Days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_delayed = pd.read_csv(\"../Data/Combined_Delayed_2Days.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_Delayed_train, X_Delayed_test, y_Delayed_train, y_Delayed_test = train_test_split(data_delayed['Tweets_clean_more'], data_delayed['Label_delayed_2Days'], test_size=0.2, random_state=42)\n",
    "\n",
    "X_Delayed_train_list = X_Delayed_train.to_list()\n",
    "X_Delayed_test_list = X_Delayed_test.to_list()\n",
    "vectorizer.fit(X_Delayed_train_list)\n",
    "vectorizer.fit(X_Delayed_test_list)\n",
    "X_Delayed_train_clean = vectorizer.transform(X_Delayed_train_list)\n",
    "X_Delayed_test_clean = vectorizer.transform(X_Delayed_test_list)\n",
    "\n",
    "X_Delayed_train_array = X_Delayed_train_clean.toarray()\n",
    "X_Delayed_test_array = X_Delayed_test_clean.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.49295774647887325\n",
      "F1 Score: 0.49295774647887325\n",
      "ROC AUC Score: 0.619718309859155\n",
      "Confusion Matrix: [[70 64  9]\n",
      " [56 70 10]\n",
      " [ 5  0  0]]\n",
      "Classification Report:               precision    recall  f1-score   support\n",
      "\n",
      "    Decrease       0.53      0.49      0.51       143\n",
      "    Increase       0.52      0.51      0.52       136\n",
      "   No Change       0.00      0.00      0.00         5\n",
      "\n",
      "    accuracy                           0.49       284\n",
      "   macro avg       0.35      0.33      0.34       284\n",
      "weighted avg       0.52      0.49      0.51       284\n",
      "\n",
      "Accuracy: 0.45774647887323944\n",
      "F1 Score: 0.45774647887323944\n",
      "ROC AUC Score: 0.5933098591549296\n",
      "Confusion Matrix: [[53 86  4]\n",
      " [52 77  7]\n",
      " [ 3  2  0]]\n",
      "Classification Report:               precision    recall  f1-score   support\n",
      "\n",
      "    Decrease       0.49      0.37      0.42       143\n",
      "    Increase       0.47      0.57      0.51       136\n",
      "   No Change       0.00      0.00      0.00         5\n",
      "\n",
      "    accuracy                           0.46       284\n",
      "   macro avg       0.32      0.31      0.31       284\n",
      "weighted avg       0.47      0.46      0.46       284\n",
      "\n",
      "Accuracy: 0.4612676056338028\n",
      "F1 Score: 0.4612676056338028\n",
      "ROC AUC Score: 0.5959507042253521\n",
      "Confusion Matrix: [[ 30  96  17]\n",
      " [ 23 100  13]\n",
      " [  1   3   1]]\n",
      "Classification Report:               precision    recall  f1-score   support\n",
      "\n",
      "    Decrease       0.56      0.21      0.30       143\n",
      "    Increase       0.50      0.74      0.60       136\n",
      "   No Change       0.03      0.20      0.06         5\n",
      "\n",
      "    accuracy                           0.46       284\n",
      "   macro avg       0.36      0.38      0.32       284\n",
      "weighted avg       0.52      0.46      0.44       284\n",
      "\n",
      "Accuracy: 0.35563380281690143\n",
      "F1 Score: 0.35563380281690143\n",
      "ROC AUC Score: 0.5167253521126761\n",
      "Confusion Matrix: [[53 48 42]\n",
      " [46 47 43]\n",
      " [ 4  0  1]]\n",
      "Classification Report:               precision    recall  f1-score   support\n",
      "\n",
      "    Decrease       0.51      0.37      0.43       143\n",
      "    Increase       0.49      0.35      0.41       136\n",
      "   No Change       0.01      0.20      0.02         5\n",
      "\n",
      "    accuracy                           0.36       284\n",
      "   macro avg       0.34      0.31      0.29       284\n",
      "weighted avg       0.50      0.36      0.41       284\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = MultinomialNB().fit(X_Delayed_train_array, y_Delayed_train)\n",
    "Y_Delayed_pred = clf.predict(X_Delayed_test_array)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_Delayed_test, Y_Delayed_pred))\n",
    "print(\"F1 Score:\", f1_score(y_Delayed_test, Y_Delayed_pred, average='micro'))\n",
    "print(\"ROC AUC Score:\", multiclass_roc_auc_score(y_Delayed_test, Y_Delayed_pred, average='micro'))\n",
    "print(\"Confusion Matrix:\", confusion_matrix(y_Delayed_test, Y_Delayed_pred))\n",
    "print(\"Classification Report:\", classification_report(y_Delayed_test, Y_Delayed_pred))\n",
    "\n",
    "clf = GaussianNB().fit(X_Delayed_train_array, y_Delayed_train)\n",
    "Y_Delayed_pred = clf.predict(X_Delayed_test_array)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_Delayed_test, Y_Delayed_pred))\n",
    "print(\"F1 Score:\", f1_score(y_Delayed_test, Y_Delayed_pred, average='micro'))\n",
    "print(\"ROC AUC Score:\", multiclass_roc_auc_score(y_Delayed_test, Y_Delayed_pred, average='micro'))\n",
    "print(\"Confusion Matrix:\", confusion_matrix(y_Delayed_test, Y_Delayed_pred))\n",
    "print(\"Classification Report:\", classification_report(y_Delayed_test, Y_Delayed_pred))\n",
    "\n",
    "clf = BernoulliNB().fit(X_Delayed_train_array, y_Delayed_train)\n",
    "Y_Delayed_pred = clf.predict(X_Delayed_test_array)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_Delayed_test, Y_Delayed_pred))\n",
    "print(\"F1 Score:\", f1_score(y_Delayed_test, Y_Delayed_pred, average='micro'))\n",
    "print(\"ROC AUC Score:\", multiclass_roc_auc_score(y_Delayed_test, Y_Delayed_pred, average='micro'))\n",
    "print(\"Confusion Matrix:\", confusion_matrix(y_Delayed_test, Y_Delayed_pred))\n",
    "print(\"Classification Report:\", classification_report(y_Delayed_test, Y_Delayed_pred))\n",
    "\n",
    "clf = ComplementNB().fit(X_Delayed_train_array, y_Delayed_train)\n",
    "Y_Delayed_pred = clf.predict(X_Delayed_test_array)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_Delayed_test, Y_Delayed_pred))\n",
    "print(\"F1 Score:\", f1_score(y_Delayed_test, Y_Delayed_pred, average='micro'))\n",
    "print(\"ROC AUC Score:\", multiclass_roc_auc_score(y_Delayed_test, Y_Delayed_pred, average='micro'))\n",
    "print(\"Confusion Matrix:\", confusion_matrix(y_Delayed_test, Y_Delayed_pred))\n",
    "print(\"Classification Report:\", classification_report(y_Delayed_test, Y_Delayed_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('anly-580')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "632cdf940b59264b613ce36e6ff44b18344167f8957438a92a721914f37336e1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
